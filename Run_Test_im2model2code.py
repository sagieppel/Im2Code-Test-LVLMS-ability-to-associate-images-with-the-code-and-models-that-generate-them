import os
import numpy as np
import random
import cv2
from tools import clean_code_comments
import tools.VisualQuestion as VQ
import json_pkl

#Im2Model2Code: Test LVLMS abitility to associate images to the code and models that generate them
# By first asking the VLM to infer the model/system beyond each image and then matching textual description of this infer model to the code
# This is done using  a multi choice question where the LVLM receive code or model verbal description
# and several images generated by the different models and is asked to find which images where generated by the described model
# This script run on the SciTextures dataset. See SciTextures paper for more details
# Run Im2Code and Im2Desc tests:
################################Run  image to image matching test ###########################################################################################

def run_test_text2im(code_main_dir,
                     images_main_dir, # images main dir (Scitexture/images/
                     relative_image_path=False, # True if the image dir is a subdir of the code dir
                     num_choices=10,  # number of choices in the multichoice tes
                     max_question=100,  # Max questions per text
                     num_samples=1,  # Number of referance image per model
                     mode="code",  # "description" # match images to code or to model description
                     display=False,  # for debug
                     error_dir="",  # error dir where mistakes will be saved
                     remove_code_comments=False,  # Remove comments from code
                     outdir="",  # output dir
                     single_image=True,
                     # Merge all images into single image (recomanded) not all LVLMs can deal with many images)
                     model=""):
    results={"correct":0,"wrong":0,"fail":0}
#-----------------Create file structure------------------------------------------
    im_data = {}
    txt_data = {}
    for dr in os.listdir(code_main_dir):
        if relative_image_path:  # if image dir is subdir of code dir
            img_dir = code_main_dir + "//" + dr + "//" + images_main_dir
        else:
            img_dir = images_main_dir + "//" + dr + "//"
        if mode == "code":  # match image to code
            file_path = code_main_dir + "//" + dr + "//generate.py"
        else:  # match image to description
            file_path = code_main_dir + "//" + dr + ("//Description.txt")
        if not os.path.exists(file_path):
            continue

        if not os.path.isdir(img_dir)  or len(os.listdir(img_dir))<num_samples: continue

        with open(file_path, "r") as fl:
            txt_data[dr] = fl.read()
            if mode == "code" and remove_code_comments:
                txt_data[dr] = clean_code_comments.remove_non_executable_code(txt_data[dr])
        im_data[dr]=[]

        for fl in os.listdir(img_dir):
            if ".jpg" in fl or ".png" in fl:
                 im_data[dr].append(img_dir+fl)


#-------------------run test-----------------------------------------------------------------------
    all_grps = list(im_data.keys())

    for  n_qst,pos_grp in enumerate(all_grps):
        if n_qst>max_question:break
        used_groups = [pos_grp]
        test_images = {}
    #---------------------------------------------------------------------------------------
        correct_indx=np.random.randint(num_choices)+1 # index of postive choice
        correct_choice = "group_" + str(correct_indx)
        options=[]

        for ii in range(1,num_choices+1):
            options.append("group_"+str(ii))
            if ii==correct_indx:
                grp = pos_grp
            else:
                while (True):
                    grp = random.sample(all_grps, 1)[0]
                    if grp not in used_groups:
                        used_groups.append(grp)
                        break

    #----------------------sample  referance------------------------------------------------------------

            samples = random.sample(im_data[grp],num_samples)
            for kk,sm in enumerate(samples):
                test_images["group_"+str(ii)+"_sample_"+str(kk+1)] = sm #im_data[grp][sm]

#--------------------------------------------------------------------------------------------------------------------------------
        # --------------Unify images (optional)----------------------------------------------
        if single_image:
            im_path = ""
            if len(outdir) > 0:
                if not os.path.exists(outdir): os.mkdir(outdir)
                im_path = outdir + "//" + str(n_qst) + ".jpg"
                json_pkl.save_json(test_images, outdir + "//" + str(n_qst) + ".json")
            im, test_images = VQ.unify_image(data=test_images, num_columns=6, labels=["group"],#options,#["reference", "test"],
                                             out_file=im_path, disp=False)

        #--------------------------------------------------------------------------------------------------------------------------------------
        outcome= "fail"

         #  ans=F3.get_response_image_json(text=txt,img_path=test_images, model="gpt-5")
        for i in range(2):
            # -------------------------Create text---------------------------------------------------------------------------
            q_txt_model = ("\n You are given set of images divided into several group named: " + str(options) +
                           "\n Each images in the same group were generated by the same model/algorithm/simulation,"
                           "\n For each group of images I want you to try and infer the model/mechanism/algorithm that form it."  # (for example monte carlo/random walk/game of life/bolzman lattice)(..."
                           "\n Your answer should come as JSON dictionary of the following format:\n"
                           "{\n'"+options[0]+"':{'model':your best estimate as to the model that form this pattern (dont explain how you got it just the model)."
                           "'explain': explanation of how you got to it}"
                           "\n'"+options[1]+"': .....}")
                          # "\nNote that the dictionary keys should include each of the following groups: " + str(  options))

            print("Answer\n"+q_txt_model)
            models_desc = VQ.get_response_image_txt_json(text=q_txt_model, img_path=test_images, model=model)
            print(models_desc)
            model_txt = ""
            for ky in models_desc:
                if 'model' in models_desc[ky]:
                    model_txt += "\n" + ky + ":  "+models_desc[ky]['model']
                else:
                    print("Missing model in ",ky ,"\n",models_desc[ky])
            qtxt = str("Here are description of several groups of algorithms/methods/models which might be inaccurate or contain errors."
                "***"+model_txt+"***"
                "\n You are also given a reference " + mode + ":"
                "***\n" + txt_data[pos_grp]+"\n ***"
                "\nWhich  of the models "+str(options)+" is most similar to the reference "+mode+
                "\nProvide your answer as json dictionary of the following structure"
                "\n{'answer': <the best suited model must be one of:" + str(options) + ">, 'explanation':<explain your answer>}")
            print(qtxt)
            ans = VQ.get_response_image_txt_json(text=qtxt, model=model)
            print(ans)
            if 'answer' in ans and ans['answer'] in options:
               if ans['answer']==correct_choice:
                   outcome= "correct"
               else:
                   outcome= "wrong"
               break
        print(outcome)

        results[outcome] += 1

        print(results)
        # ***************************Display and save **********************************************************
        # ================== save============
        if len(error_dir) > 0:# and (outcome == "wrong" or outcome == "fail"):
            if not os.path.exists(error_dir): os.mkdir(error_dir)
            spec_er_dir = os.path.join(error_dir, pos_grp)
            if not os.path.exists(spec_er_dir): os.mkdir(spec_er_dir)
            txt=q_txt_model+ "\n\nAnswer:\n\n"+str(models_desc) +"\n" +  qtxt + "\n\nAnswer:\n\n"+str(ans)
            with open(spec_er_dir+"/QA.txt","w") as fl: fl.write(txt)
            json_pkl.save_json({"q1":q_txt_model,"a1":models_desc,"q2":qtxt,"a2":ans},spec_er_dir+"/QA.json")
            json_pkl.save_pkl({"q1": q_txt_model, "a1": models_desc, "q2": qtxt, "a2": ans}, spec_er_dir + "/QA.pickle")

            for ky in test_images:
                if ky == correct_choice:
                    cv2.imwrite(spec_er_dir + "//" + ky + "correct.jpg", cv2.imread(test_images[ky]))
                elif ("answer" in ans) and ky == ans["answer"]:
                    cv2.imwrite(spec_er_dir + "//" + ky + "choice.jpg", cv2.imread(test_images[ky]))
                else:
                    cv2.imwrite(spec_er_dir + "//" + ky + ".jpg", cv2.imread(test_images[ky]))
            with open(spec_er_dir + "//data.txt", "w") as fl:
                fl.write(pos_grp + "\n" + str(ans) + "\ncorrect" + correct_choice)
        #-----------------------------------------------------------------------------------
        # display
        if display:
            for ky in test_images:
                if ky == correct_choice:
                    cv2.imshow(ky + "correct", cv2.imread(test_images[ky]))
                else:
                    cv2.imshow(ky + "  " + grp, cv2.imread(test_images[ky]))
                    print(grp)
            cv2.waitKey()
        # =*******************************************************
        #-------------------------------------------------------------------------------------


    results["accuracy"] = results["correct"]/(results["wrong"]+results["fail"]+results["correct"])
    return results

##############################################################################################################




############################################main ###########################################################################################
if __name__ == "__main__":
    # >>>>> EDIT PATH BELOW TO YOUR DATA ROOT <<<<<
    code_main_dir = r"Scitexture/code_and_data/" # Code main dir from the SciTextures dataset
    images_main_dir = r"Scitexture/images/" # Image main dir from the SciTextures dataset
    out_dir = r"output_Result_dir//" # Output dir where results will be saved
    error_dir = out_dir + "//Fail//" # Output subdir were the fail cases (where the model was wrong will be saved)
    model = "gpt-5"#, "human"

    run_test_text2im(code_main_dir=code_main_dir,
                    images_main_dir=images_main_dir,  # images main dir (Scitexture/images/
                    num_choices=10,  # number of choices in the multichoice tes
                    max_question=100,  # Max questions per text
                    num_samples=3,  # Number of referance image per model
                    mode="code",  # "description" # match images to code or to model description
                    error_dir=error_dir,  # error dir where mistakes will be saved
                    remove_code_comments=False,  # Remove comments from code
                    outdir=out_dir,  # output dir
                    model=model)
